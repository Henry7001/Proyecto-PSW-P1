{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Henry7001/Proyecto-PSW-P1/blob/main/scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ34RjasQeBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4c8dfc-5b53-4832-e50f-82d125d6e3a1"
      },
      "source": [
        "%pip install Colorama\n",
        "%pip install BeautifulSoup4\n",
        "%pip install requests\n",
        "%pip install pandas\n",
        "%pip install WordCloud\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: Colorama\n",
            "Successfully installed Colorama-0.4.4\n",
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: WordCloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from WordCloud) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from WordCloud) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UAHVs7P-lRZ"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "import string\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from wordcloud import WordCloud, STOPWORDS\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from colorama import init, Fore\r\n",
        "from google.colab import output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUDcnVieEtFj"
      },
      "source": [
        "\n",
        "def loop(n, p):\n",
        "    y = 0\n",
        "    while y < n:\n",
        "        y = y + 1\n",
        "        tex.write(\"\\t\"+p)\n",
        "\n",
        "def scraping(id,etiq):\n",
        "    url = 'https://es.stackoverflow.com/users/'+id+'/?tab=tags'\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    while page.status_code!=200:\n",
        "        print(\"No se encontró al usuario con ese ID\")\n",
        "        idr=input(\"Ingrese el id de usuario a extraer informacion: \")\n",
        "        url = 'https://es.stackoverflow.com/users/' + idr + '/?tab=tags'\n",
        "        page = requests.get(url)\n",
        "        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "    Tags = soup.find_all('a', class_='post-tag')\n",
        "    Points = soup.find_all('div', class_='answer-votes')\n",
        "    etiquetas = list()\n",
        "\n",
        "    for i in Tags:\n",
        "        etiquetas.append(i.text)\n",
        "\n",
        "    puntos = list()\n",
        "\n",
        "    for i in Points:\n",
        "        puntos.append(i.text.replace('k','000'))\n",
        "\n",
        "    for i in range(len(etiquetas)-1):\n",
        "      if int(puntos[i])>0:\n",
        "        etiq[etiquetas[i]] = int(puntos[i])\n",
        "\n",
        "def wordcloud(etiq):\n",
        "    x = 0\n",
        "    for x in etiq:\n",
        "      if etiq[x]>0:\n",
        "        n=etiq[x]\n",
        "        p = x\n",
        "        loop(n, p)\n",
        "    tex.close()\n",
        "    with open(\"Datos.txt\", encoding='utf-8')as file: \n",
        "      text = file.read()\n",
        "      normal_word = r\"(?:\\w[\\w']+)\"\n",
        "      ascii_art = r\"(?:\\w[{punctuation}][{punctuation}]+)\".format(punctuation=string.punctuation)\n",
        "      c= r\"(?:\\w[{punctuation}]+)\".format(punctuation=string.punctuation)\n",
        "      emoji = r\"(?<![\\w{ascii_printable}])\".format(ascii_printable=string.printable)\n",
        "      regexp = r\"{normal_word}|{ascii_art}|{emoji}|{c}\".format( normal_word = normal_word,ascii_art=ascii_art,emoji=emoji,c=c)\n",
        "     \n",
        "      cloud = WordCloud(background_color=\"white\", collocations=False,regexp=regexp).generate(text)\n",
        "      plt.imshow(cloud)\n",
        "      plt.axis('off') \n",
        "      plt.show()\n",
        "\n",
        "def start():\n",
        "    id = input(\"Ingrese el id de usuario a extraer informacion: \")\n",
        "    etiq = {}\n",
        "    scraping(id,etiq)\n",
        "    print(\"Etiquetas del usuario: \"); print(etiq)\n",
        "    #print(etiq)\n",
        "    #print(\"\\n\")\n",
        "    if etiq: \n",
        "        wordcloud(etiq)\n",
        "    else:\n",
        "        print(\"El usuario tiene 0 puntos o no tiene etiqueta.\\n  No se pudo generar el WordCloud\")\n",
        "    \n",
        "    \n",
        "\n",
        "while True:\n",
        "    output.clear()\n",
        "    tex = open(\"Datos.txt\", \"w\")\n",
        "    print(\"Bienvenido a la aplicación\")\n",
        "    start()\n",
        "    x=str(input(\"¿Desea continuar? Escriba exit para Salir o cualquier palabra para continuar: \"))\n",
        "    if x==\"exit\":\n",
        "        output.clear()\n",
        "        #fin()\n",
        "        print('Gracias por usar la app')\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
