{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ34RjasQeBR"
      },
      "source": [
        "%pip install BeautifulSoup4\n",
        "%pip install requests\n",
        "%pip install pandas\n",
        "%pip install WordCloud\n",
        "%pip install Colorama\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UAHVs7P-lRZ"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "import string\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from wordcloud import WordCloud, STOPWORDS\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from colorama import init, Fore\r\n",
        "from google.colab import output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUDcnVieEtFj"
      },
      "source": [
        "\n",
        "def ciclo(n, p):\n",
        "    y = 0\n",
        "    while y < n:\n",
        "        y = y + 1\n",
        "        tex.write(\"\\t\"+p)\n",
        "\n",
        "def scraping(v,tagdict):\n",
        "    url = 'https://es.stackoverflow.com/users/'+v+'/?tab=tags'\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    while page.status_code!=200:\n",
        "        print(\"  ID de usuario no valido\")\n",
        "        x=input(\"Ingrese el id de usuario a extraer informacion: \")\n",
        "        url = 'https://es.stackoverflow.com/users/' + x + '/?tab=tags'\n",
        "        page = requests.get(url)\n",
        "        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "        #Usuario\n",
        "    Tags = soup.find_all('a', class_='post-tag')\n",
        "    Points = soup.find_all('div', class_='answer-votes')\n",
        "    #print(User)\n",
        "    etiquetas = list()\n",
        "\n",
        "    for i in Tags:\n",
        "        etiquetas.append(i.text)\n",
        "\n",
        "    puntos = list()\n",
        "\n",
        "    for i in Points:\n",
        "        puntos.append(i.text.replace('k','000'))\n",
        "\n",
        "    for i in range(len(etiquetas)-1):\n",
        "      if int(puntos[i])>0:\n",
        "        tagdict[etiquetas[i]] = int(puntos[i])\n",
        "\n",
        "def wordcloud(tagdict):\n",
        "    x = 0\n",
        "    # recorre el diccionario y envie el valor y la clave\n",
        "    for x in tagdict:\n",
        "      if tagdict[x]>0:\n",
        "        n=tagdict[x]\n",
        "        p = x\n",
        "        ciclo(n, p)\n",
        "    tex.close()\n",
        "    with open(\"Datos.txt\", encoding='utf-8')as file: \n",
        "      text = file.read()\n",
        "      normal_word = r\"(?:\\w[\\w']+)\"\n",
        "      ascii_art = r\"(?:\\w[{punctuation}][{punctuation}]+)\".format(punctuation=string.punctuation)\n",
        "      c= r\"(?:\\w[{punctuation}]+)\".format(punctuation=string.punctuation)\n",
        "      emoji = r\"(?<![\\w{ascii_printable}])\".format(ascii_printable=string.printable)\n",
        "      regexp = r\"{normal_word}|{ascii_art}|{emoji}|{c}\".format( normal_word = normal_word,ascii_art=ascii_art,emoji=emoji,c=c)\n",
        "     \n",
        "      cloud = WordCloud(background_color=\"white\", collocations=False,regexp=regexp).generate(text)\n",
        "      plt.imshow(cloud)\n",
        "      plt.axis('off') \n",
        "      plt.show()\n",
        "\n",
        "def inicio():\n",
        "    v = input(\"\\n\\n  Ingrese el id de usuario a extraer informacion: \")\n",
        "    tagdict = {}\n",
        "    scraping(v,tagdict)\n",
        "    print(\"\\n  SE OBTUVIERON LAS SIGUENTES ETIQUETAS \\n\")\n",
        "    print(tagdict)\n",
        "    print(\"\\n\")\n",
        "    if tagdict: \n",
        "        wordcloud(tagdict)\n",
        "    else:\n",
        "     print(\"El usuario tiene 0 puntos o no tiene etiqueta.\\n  No se pudo generar el WordCloud\")\n",
        "\n",
        "#print(\" Bienvenido\")\n",
        "while True:\n",
        "    output.clear()\n",
        "    tex = open(\"Datos.txt\", \"w\")\n",
        "    inicio()\n",
        "    x=str(input(\"\\n    ¿Desea continuar? Escriba 1 para Salir o cualquier carácter para continuar: \"))\n",
        "    if x==\"1\":\n",
        "        output.clear()\n",
        "        #fin()\n",
        "        print('Gracias por usar la app')\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}